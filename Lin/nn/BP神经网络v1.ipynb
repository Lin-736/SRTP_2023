{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ede1562",
   "metadata": {},
   "source": [
    "需要import的package。\n",
    "第一个是python的numpy科学计算库，可以将矩阵向量化，避免显示for循环，大幅提升运算速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8874b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063abfe",
   "metadata": {},
   "source": [
    "激活函数是每个隐藏层节点和输出层的输出，输入和权重矩阵相乘，加上初始偏置值后，再作为激活函数自变量，映射后进行输出。\n",
    "\n",
    "relu函数即线性激活函数，定义为：(python中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6cf8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义激活函数\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d4602",
   "metadata": {},
   "source": [
    "除此之外，还有带泄露的relu函数：\n",
    "\n",
    "（本次运算中，带泄露的relu函数并不会用到）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdc65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_2(x):\n",
    "   \n",
    "   if x>=0:\n",
    "     \n",
    "     return np.maximum(x, 0)\n",
    "   \n",
    "   if x>=0:\n",
    "     \n",
    "     return np.minimum(0.01*x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af9599",
   "metadata": {},
   "source": [
    "除此之外，还有signoid函数和tanh函数，这两个函数都是为了将输出归一到[-1,1]，同时这两个函数还是非线性函数，事实上只有非线性的输出才能进行拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2460834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络类\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # 初始化权重和偏置\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.random.randn(hidden_size)\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 前向传播计算\n",
    "        Z1 = np.dot(X, self.W1) + self.b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        return Z2\n",
    "\n",
    "    def train(self, X, y, learning_rate=0.01, max_epochs=1000):\n",
    "        # 训练模型\n",
    "        for epoch in range(max_epochs):\n",
    "            # 前向传播计算\n",
    "            Z1 = np.dot(X, self.W1) + self.b1\n",
    "            A1 = relu(Z1)\n",
    "            Z2 = np.dot(A1, self.W2) + self.b2\n",
    "\n",
    "            # 计算误差\n",
    "            loss = np.mean((Z2 - y) ** 2)\n",
    "\n",
    "            # 反向传播更新权重和偏置\n",
    "            dZ2 = Z2 - y\n",
    "            dW2 = np.dot(A1.T, dZ2)\n",
    "            db2 = np.sum(dZ2, axis=0)\n",
    "            dA1 = np.dot(dZ2, self.W2.T)\n",
    "            dZ1 = dA1 * (Z1 > 0)\n",
    "            dW1 = np.dot(X.T, dZ1)\n",
    "            db1 = np.sum(dZ1, axis=0)\n",
    "\n",
    "            self.W1 -= learning_rate * dW1\n",
    "            self.b1 -= learning_rate * db1\n",
    "            self.W2 -= learning_rate * dW2\n",
    "            self.b2 -= learning_rate * db2\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(\"Epoch %d, Loss = %f\" % (epoch, loss))\n",
    "                print(dW1)\n",
    "                print(\"\\n\")\n",
    "                print(db2)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6901621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 224076.673109\n",
      "[[-1.68128023e+04  0.00000000e+00 -4.85468602e+02  6.66473119e+02\n",
      "  -2.22290902e+04]\n",
      " [-5.85120447e+05  0.00000000e+00 -1.68953159e+04  2.31946491e+04\n",
      "  -7.73618518e+05]\n",
      " [-1.73160112e+04  0.00000000e+00 -4.99998727e+02  6.86420728e+02\n",
      "  -2.28944092e+04]\n",
      " [-1.46910607e+04  0.00000000e+00 -4.24203447e+02  5.82365561e+02\n",
      "  -1.94238240e+04]]\n",
      "\n",
      "\n",
      "[-5198.29130824     0.          -150.1003325    206.06448354\n",
      " -6872.93435043]\n",
      "Epoch 500, Loss = 1200806.463200\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 1000, Loss = 69376.693218\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 1500, Loss = 69370.228164\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 2000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 2500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 3000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 3500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 4000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 4500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 5000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 5500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 6000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 6500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 7000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 7500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 8000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 8500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 9000, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "Epoch 9500, Loss = 69370.228127\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetwork at 0x2325fa23430>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建神经网络模型\n",
    "input_size = 4\n",
    "hidden_size1 = 5\n",
    "output_size = 1\n",
    "model = NeuralNetwork(input_size, hidden_size1,output_size)\n",
    "\n",
    "# 12组数据作为训练集X和标签y\n",
    "X_train = np.array([[3, 100, 4, 1], [3, 80, 8, 1], [2, 130, 1, 1], [1, 150, 2, 2], [5, 120, 4, 3],[2,100,4,4],[4,80,2,3],[4,120,2,3], [3,120,2,3], [3,120,5,3], [2,120,5,3], [2,80,5,1]])\n",
    "y_train = np.array([305.427684, 195.427684, 431.945280, 438.591409, 1127.065795, 861.945280, 587.990750, 707.990750 ,535.427685 ,469.331280, 405.848876, 165.848876]).reshape(-1,1)\n",
    "\n",
    "# 训练模型\n",
    "model.train(X_train, y_train, learning_rate=0.001, max_epochs=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b18cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[519.40344575]\n"
     ]
    }
   ],
   "source": [
    "# 预测房价\n",
    "X_test = np.array([1, 100, 3, 5])\n",
    "y_pred = model.forward(X_test)\n",
    "rate=y_pred/261.945280\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e368a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
